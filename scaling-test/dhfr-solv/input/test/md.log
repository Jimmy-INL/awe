Log file opened on Wed Feb 29 23:37:55 2012
Host: haldarfe.crc.nd.edu  pid: 30229  nodeid: 0  nnodes:  1
The Gromacs distribution was built Mon Dec  6 16:48:29 EST 2010 by
cabdulwa@haldarfe.crc.nd.edu (Linux 2.6.18-194.26.1.el5 x86_64)


                         :-)  G  R  O  M  A  C  S  (-:

                              S  C  A  M  O  R  G

                            :-)  VERSION 4.5.3  (-:

        Written by Emile Apol, Rossen Apostolov, Herman J.C. Berendsen,
      Aldert van Buuren, PÃ¤r Bjelkmar, Rudi van Drunen, Anton Feenstra, 
        Gerrit Groenhof, Peter Kasson, Per Larsson, Pieter Meulenhoff, 
           Teemu Murtola, Szilard Pall, Sander Pronk, Roland Schulz, 
                Michael Shirts, Alfons Sijbers, Peter Tieleman,

               Berk Hess, David van der Spoel, and Erik Lindahl.

       Copyright (c) 1991-2000, University of Groningen, The Netherlands.
            Copyright (c) 2001-2010, The GROMACS development team at
        Uppsala University & The Royal Institute of Technology, Sweden.
            check out http://www.gromacs.org for more information.

         This program is free software; you can redistribute it and/or
          modify it under the terms of the GNU General Public License
         as published by the Free Software Foundation; either version 2
             of the License, or (at your option) any later version.

                                :-)  mdrun  (-:


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess and C. Kutzner and D. van der Spoel and E. Lindahl
GROMACS 4: Algorithms for highly efficient, load-balanced, and scalable
molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 435-447
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A. E. Mark and H. J. C.
Berendsen
GROMACS: Fast, Flexible and Free
J. Comp. Chem. 26 (2005) pp. 1701-1719
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
E. Lindahl and B. Hess and D. van der Spoel
GROMACS 3.0: A package for molecular simulation and trajectory analysis
J. Mol. Mod. 7 (2001) pp. 306-317
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
H. J. C. Berendsen, D. van der Spoel and R. van Drunen
GROMACS: A message-passing parallel molecular dynamics implementation
Comp. Phys. Comm. 91 (1995) pp. 43-56
-------- -------- --- Thank You --- -------- --------

Input Parameters:
   integrator           = md
   nsteps               = 1000
   init_step            = 0
   ns_type              = Grid
   nstlist              = 10
   ndelta               = 2
   nstcomm              = 10
   comm_mode            = Linear
   nstlog               = 0
   nstxout              = 0
   nstvout              = 0
   nstfout              = 0
   nstcalcenergy        = 10
   nstenergy            = 0
   nstxtcout            = 0
   init_t               = 0
   delta_t              = 0.002
   xtcprec              = 1000
   nkx                  = 64
   nky                  = 64
   nkz                  = 64
   pme_order            = 4
   ewald_rtol           = 1e-05
   ewald_geometry       = 0
   epsilon_surface      = 0
   optimize_fft         = FALSE
   ePBC                 = xyz
   bPeriodicMols        = FALSE
   bContinuation        = FALSE
   bShakeSOR            = FALSE
   etc                  = Berendsen
   nsttcouple           = 10
   epc                  = No
   epctype              = Isotropic
   nstpcouple           = -1
   tau_p                = 1
   ref_p (3x3):
      ref_p[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      ref_p[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      ref_p[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   compress (3x3):
      compress[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      compress[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      compress[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   refcoord_scaling     = No
   posres_com (3):
      posres_com[0]= 0.00000e+00
      posres_com[1]= 0.00000e+00
      posres_com[2]= 0.00000e+00
   posres_comB (3):
      posres_comB[0]= 0.00000e+00
      posres_comB[1]= 0.00000e+00
      posres_comB[2]= 0.00000e+00
   andersen_seed        = 815131
   rlist                = 1.1
   rlistlong            = 1.1
   rtpi                 = 0.05
   coulombtype          = PME-Switch
   rcoulomb_switch      = 0
   rcoulomb             = 0.9
   vdwtype              = Shift
   rvdw_switch          = 0
   rvdw                 = 0.9
   epsilon_r            = 1
   epsilon_rf           = inf
   tabext               = 1
   implicit_solvent     = No
   gb_algorithm         = Still
   gb_epsilon_solvent   = 80
   nstgbradii           = 1
   rgbradii             = 1
   gb_saltconc          = 0
   gb_obc_alpha         = 1
   gb_obc_beta          = 0.8
   gb_obc_gamma         = 4.85
   gb_dielectric_offset = 0.009
   sa_algorithm         = Ace-approximation
   sa_surface_tension   = 2.05016
   DispCorr             = No
   free_energy          = no
   init_lambda          = 0
   delta_lambda         = 0
   n_foreign_lambda     = 0
   sc_alpha             = 0
   sc_power             = 0
   sc_sigma             = 0.3
   sc_sigma_min         = 0.3
   nstdhdl              = 10
   separate_dhdl_file   = yes
   dhdl_derivatives     = yes
   dh_hist_size         = 0
   dh_hist_spacing      = 0.1
   nwall                = 0
   wall_type            = 9-3
   wall_atomtype[0]     = -1
   wall_atomtype[1]     = -1
   wall_density[0]      = 0
   wall_density[1]      = 0
   wall_ewald_zfac      = 3
   pull                 = no
   disre                = No
   disre_weighting      = Conservative
   disre_mixed          = FALSE
   dr_fc                = 1000
   dr_tau               = 0
   nstdisreout          = 100
   orires_fc            = 0
   orires_tau           = 0
   nstorireout          = 100
   dihre-fc             = 1000
   em_stepsize          = 0.01
   em_tol               = 10
   niter                = 20
   fc_stepsize          = 0
   nstcgsteep           = 1000
   nbfgscorr            = 10
   ConstAlg             = Lincs
   shake_tol            = 0.0001
   lincs_order          = 4
   lincs_warnangle      = 30
   lincs_iter           = 1
   bd_fric              = 0
   ld_seed              = 1993
   cos_accel            = 0
   deform (3x3):
      deform[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   userint1             = 0
   userint2             = 0
   userint3             = 0
   userint4             = 0
   userreal1            = 0
   userreal2            = 0
   userreal3            = 0
   userreal4            = 0
grpopts:
   nrdf:       47112
   ref_t:         300
   tau_t:         0.1
anneal:          No
ann_npoints:           0
   acc:	           0           0           0
   nfreeze:           N           N           N
   energygrp_flags[  0]: 0
   efield-x:
      n = 0
   efield-xt:
      n = 0
   efield-y:
      n = 0
   efield-yt:
      n = 0
   efield-z:
      n = 0
   efield-zt:
      n = 0
   bQMMM                = FALSE
   QMconstraints        = 0
   QMMMscheme           = 0
   scalefactor          = 1
qm_opts:
   ngQM                 = 0

Initializing Domain Decomposition on 24 nodes
Dynamic load balancing: auto
Will sort the charge groups at every domain (re)decomposition
Initial maximum inter charge-group distances:
    two-body bonded interactions: 0.425 nm, LJ-14, atoms 233 241
  multi-body bonded interactions: 0.425 nm, Proper Dih., atoms 233 241
Minimum cell size due to bonded interactions: 0.468 nm
Maximum distance for 5 constraints, at 120 deg. angles, all-trans: 0.819 nm
Estimated maximum distance required for P-LINCS: 0.819 nm
This distance will limit the DD cell size, you can override this with -rcon
Guess for relative PME load: 0.24
Will use 18 particle-particle and 6 PME only nodes
This is a guess, check the performance at the end of the log file
Using 6 separate PME nodes
Scaling the initial minimum size with 1/0.8 (option -dds) = 1.25
Optimizing the DD grid for 18 cells with a minimum initial size of 1.024 nm
The maximum allowed number of cells is: X 6 Y 6 Z 6
Domain decomposition grid 6 x 3 x 1, separate PME nodes 6
PME domain decomposition: 6 x 1 x 1
Interleaving PP and PME nodes
This is a particle-particle only node

Domain decomposition nodeid 0, coordinates 0 0 0

Table routines are used for coulomb: TRUE
Table routines are used for vdw:     TRUE
Will do PME sum in reciprocal space.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essman, L. Perela, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Will do ordinary reciprocal space Ewald sum.
Using a Gaussian width (1/beta) of 0.288146 nm for Ewald
Using shifted Lennard-Jones, switch between 0 and 0.9 nm
Cut-off's:   NS: 1.1   Coulomb: 0.9   LJ: 0.9
System total charge: -0.000
Generated table with 1050 data points for Ewald-Switch.
Tabscale = 500 points/nm
Generated table with 1050 data points for LJ6Shift.
Tabscale = 500 points/nm
Generated table with 1050 data points for LJ12Shift.
Tabscale = 500 points/nm
Generated table with 1050 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1050 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1050 data points for 1-4 LJ12.
Tabscale = 500 points/nm

Enabling SPC-like water optimization for 7023 molecules.

Configuring nonbonded kernels...
Configuring standard C nonbonded kernels...
Testing x86_64 SSE2 support... present.


Removing pbc first time

Initializing Parallel LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess
P-LINCS: A Parallel Linear Constraint Solver for molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 116-122
-------- -------- --- Thank You --- -------- --------

The number of constraints is 2523
There are inter charge-group constraints,
will communicate selected coordinates each lincs iteration

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Linking all bonded interactions to atoms
There are 13640 inter charge-group exclusions,
will use an extra communication step for exclusion forces for PME-Switch

The initial number of communication pulses is: X 2 Y 1
The initial domain decomposition cell size is: X 1.04 nm Y 2.07 nm

The maximum allowed distance for charge groups involved in interactions is:
                 non-bonded interactions           1.100 nm
            two-body bonded interactions  (-rdd)   1.100 nm
          multi-body bonded interactions  (-rdd)   1.037 nm
  atoms separated by up to 5 constraints  (-rcon)  1.037 nm

When dynamic load balancing gets turned on, these settings will change to:
The maximum number of communication pulses is: X 2 Y 2
The minimum size for domain decomposition cells is 0.819 nm
The requested allowed shrink of DD cells (option -dds) is: 0.80
The allowed shrink of domain decomposition cells is: X 0.79 Y 0.40
The maximum allowed distance for charge groups involved in interactions is:
                 non-bonded interactions           1.100 nm
            two-body bonded interactions  (-rdd)   1.100 nm
          multi-body bonded interactions  (-rdd)   0.819 nm
  atoms separated by up to 5 constraints  (-rcon)  0.819 nm


Making 2D domain decomposition grid 6 x 3 x 1, home cell index 0 0 0

Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
H. J. C. Berendsen, J. P. M. Postma, A. DiNola and J. R. Haak
Molecular dynamics with coupling to an external bath
J. Chem. Phys. 81 (1984) pp. 3684-3690
-------- -------- --- Thank You --- -------- --------

There are: 23569 Atoms
Charge group distribution at step 0: 358 425 399 450 673 520 552 820 482 492 790 492 476 710 480 444 508 452
Grid: 5 x 5 x 9 cells

Constraining the starting coordinates (step 0)

Constraining the coordinates at t0-dt (step 0)
RMS relative constraint deviation after constraining: 0.00e+00
Initial temperature: 291.637 K

Started mdrun on node 0 Wed Feb 29 23:37:55 2012

           Step           Time         Lambda
              0        0.00000        0.00000

   Energies (kJ/mol)
          Angle    Proper Dih.  Improper Dih.          LJ-14     Coulomb-14
    3.73306e+03    6.99046e+03    2.88470e+02    2.66787e+03    2.89976e+04
        LJ (SR)   Coulomb (SR)   Coul. recip.      Potential    Kinetic En.
    5.28048e+04   -3.16162e+05   -7.95025e+04   -3.00183e+05    5.71174e+04
   Total Energy    Temperature Pressure (bar)   Constr. rmsd
   -2.43065e+05    2.91629e+02    1.52466e+03    0.00000e+00

DD  step 9 load imb.: force 65.0%  pme mesh/force 1.541

At step 10 the performance loss due to force load imbalance is 14.4 %

NOTE: Turning on dynamic load balancing

DD  step 999  vol min/aver 0.557  load imb.: force  1.4%  pme mesh/force 0.882

           Step           Time         Lambda
           1000        2.00000        0.00000

Writing checkpoint, step 1000 at Wed Feb 29 23:38:01 2012


   Energies (kJ/mol)
          Angle    Proper Dih.  Improper Dih.          LJ-14     Coulomb-14
    3.95124e+03    6.70100e+03    2.47095e+02    2.72697e+03    2.90944e+04
        LJ (SR)   Coulomb (SR)   Coul. recip.      Potential    Kinetic En.
    4.83462e+04   -3.09814e+05   -7.95875e+04   -2.98335e+05    5.87349e+04
   Total Energy    Temperature Pressure (bar)   Constr. rmsd
   -2.39600e+05    2.99887e+02    3.74655e+02    2.88294e-05

	<======  ###############  ==>
	<====  A V E R A G E S  ====>
	<==  ###############  ======>

	Statistics over 1001 steps using 101 frames

   Energies (kJ/mol)
          Angle    Proper Dih.  Improper Dih.          LJ-14     Coulomb-14
    3.97211e+03    6.85375e+03    2.86987e+02    2.65028e+03    2.89422e+04
        LJ (SR)   Coulomb (SR)   Coul. recip.      Potential    Kinetic En.
    4.88881e+04   -3.10277e+05   -7.94430e+04   -2.98126e+05    5.85768e+04
   Total Energy    Temperature Pressure (bar)   Constr. rmsd
   -2.39550e+05    2.99080e+02    4.08848e+02    0.00000e+00

   Total Virial (kJ/mol)
    1.66642e+04   -2.38850e+02   -1.27324e+02
   -2.28859e+02    1.63586e+04   -3.61876e+01
   -1.24767e+02   -4.11920e+01    1.66536e+04

   Pressure (bar)
    4.00161e+02    3.84080e+01    1.51477e+01
    3.70312e+01    4.34693e+02    2.25798e+00
    1.47953e+01    2.94763e+00    3.91689e+02

   Total Dipole (D)
    9.64044e+02   -1.00038e+02    3.02483e+02


	M E G A - F L O P S   A C C O U N T I N G

   RF=Reaction-Field  FE=Free Energy  SCFE=Soft-Core/Free Energy
   T=Tabulated        W3=SPC/TIP3p    W4=TIP4p (single or pairs)
   NF=No Forces

 Computing:                               M-Number         M-Flops  % Flops
-----------------------------------------------------------------------------
 Coul(T)                                201.254745        8452.699     2.1
 Coul(T) [W3]                             0.746181          93.273     0.0
 Coul(T) + VdW(T)                       469.946192       31956.341     7.8
 Coul(T) + VdW(T) [W3]                   95.217942       14377.909     3.5
 Coul(T) + VdW(T) [W3-W3]               606.553386      239588.587    58.7
 Outer nonbonded loop                   127.578350        1275.784     0.3
 1,4 nonbonded interactions               6.562556         590.630     0.1
 Calc Weights                            70.777707        2547.997     0.6
 Spread Q Bspline                      1509.924416        3019.849     0.7
 Gather F Bspline                      1509.924416        9059.546     2.2
 3D-FFT                                9446.621184       75572.969    18.5
 Solve PME                              135.303168        8659.403     2.1
 NS-Pairs                               302.140037        6344.941     1.6
 Reset In Box                             0.961823           2.885     0.0
 CG-CoM                                   2.404038           7.212     0.0
 Angles                                   4.565561         767.014     0.2
 Propers                                  9.028019        2067.416     0.5
 Virial                                   2.462279          44.321     0.0
 Stop-CM                                  2.380469          23.805     0.0
 Calc-Ekin                               23.616138         637.636     0.2
 Lincs                                    5.215285         312.917     0.1
 Lincs-Mat                              111.553284         446.213     0.1
 Constraint-V                            31.532128         252.257     0.1
 Constraint-Vir                           2.653188          63.677     0.0
 Settle                                   7.044069        2275.234     0.6
-----------------------------------------------------------------------------
 Total                                                  408440.517   100.0
-----------------------------------------------------------------------------


    D O M A I N   D E C O M P O S I T I O N   S T A T I S T I C S

 av. #atoms communicated per step for force:  2 x 48569.2
 av. #atoms communicated per step for LINCS:  2 x 2826.4

 Average load imbalance: 3.5 %
 Part of the total run time spent waiting due to load imbalance: 2.3 %
 Steps where the load balancing was limited by -rdd, -rcon and/or -dds: X 0 % Y 0 %
 Average PME mesh/force load: 0.873
 Part of the total run time spent waiting due to PP/PME imbalance: 2.6 %


     R E A L   C Y C L E   A N D   T I M E   A C C O U N T I N G

 Computing:         Nodes     Number     G-Cycles    Seconds     %
-----------------------------------------------------------------------
 Domain decomp.        18        101        4.963        2.5     1.6
 DD comm. load         18        100        0.074        0.0     0.0
 DD comm. bounds       18        100        0.119        0.1     0.0
 Send X to PME         18       1001        0.900        0.5     0.3
 Comm. coord.          18       1001        2.499        1.3     0.8
 Neighbor search       18        101       20.741       10.4     6.7
 Force                 18       1001      165.573       83.0    53.7
 Wait + Comm. F        18       1001       15.292        7.7     5.0
 PME mesh               6       1001       53.752       26.9    17.4
 Wait + Comm. X/F       6                  23.288       11.7     7.6
 Wait + Recv. PME F    18       1001        0.805        0.4     0.3
 Write traj.           18          1        0.253        0.1     0.1
 Update                18       1001        2.743        1.4     0.9
 Constraints           18       1001       12.924        6.5     4.2
 Comm. energies        18        102        2.340        1.2     0.8
 Rest                  18                   1.965        1.0     0.6
-----------------------------------------------------------------------
 Total                 24                 308.231      154.5   100.0
-----------------------------------------------------------------------
-----------------------------------------------------------------------
 PME redist. X/F        6       2002        3.087        1.5     1.0
 PME spread/gather      6       2002       23.636       11.8     7.7
 PME 3D-FFT             6       2002       21.151       10.6     6.9
 PME solve              6       1001        5.856        2.9     1.9
-----------------------------------------------------------------------

	Parallel run - timing based on wallclock.

               NODE (s)   Real (s)      (%)
       Time:      6.438      6.438    100.0
               (Mnbf/s)   (GFlops)   (ns/day)  (hour/ns)
Performance:    996.905     63.442     26.867      0.893
Finished mdrun on node 0 Wed Feb 29 23:38:01 2012
