""" Analyses of data produced by the Adaptive Weighted Ensemble
"""
import numpy as np
import scipy.io
import os
import sys

def populations():
    weightsfile = 'weighthistory.txt'
    WINDOW = 50
    IGNORE = 50
    NUMSTATES = 38
    weightings=np.repeat(1.0, WINDOW) / WINDOW	
    wts=np.loadtxt(weightsfile)
    hi=wts.transpose()
    means = np.empty(NUMSTATES)
    devs  = np.empty(NUMSTATES)
    for i in range(NUMSTATES+1):
        hi1=np.convolve(hi[i,:], weightings)[WINDOW-1:-(WINDOW-1)]
        means[i-1]=np.mean(hi1[IGNORE:])
        devs[i-1]=np.std(hi1[IGNORE:])
    return means, devs

if __name__=="__main__":
    """ compute flux into cells
    using sum_i (w_i * N_ij / Ti) where the i are walkers with weight w_i 
    that crossed into state j N_ij times 
    with lifetime Ti before crossing into j 
    dt is the sampling time in ps """
    numstates = 38
    matrices = []
    weights = np.zeros((numstates+1,1))
    N = np.zeros((39,39))
    trajname = 'discrete.traj'
    FnTUnSym ="tCounts.UnSym.mtx"
    print sys.argv[1]
    dir = sys.argv[1]
    # get all discrete trajectories and transition count matrices for all RUNs except j
    for top, dirs, files in os.walk("data.100"):
        for nm in files:
            if nm == (trajname):
                traj=np.loadtxt(os.path.join(top,nm))
                w=np.loadtxt(os.path.join(top,"../weight.txt"))
                weights[traj[0]]=w
                t=scipy.io.mmread(os.path.join(top,"tCounts.UnSym.mtx"))
                matrices.append(t)
    # compress matrices
    n=np.zeros((39,39))
    for i in range(len(matrices)):
        N += matrices[i]
    ww = weights.transpose()
    NT = N.transpose()
    flowin = np.dot(ww,N) - ww*np.diag(N)
    flowout = np.dot(ww,NT) - ww*np.diag(NT)

    

    


        
                     
    
